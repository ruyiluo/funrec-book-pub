
总结
----

从“匹配”到“搜索”
~~~~~~~~~~~~~~~~

向量召回的最大贡献在于将推荐从复杂的“匹配”问题简化为高效的“搜索”问题。这一转变的基石是学习高质量的嵌入表示——将用户和物品从离散的ID符号映射到连续的向量空间中，让“距离”具有了语义意义。通过这种方式，原本需要\ :math:`O(U \times I)`\ 复杂度的用户-物品匹配问题，被优雅地转化为\ :math:`O(\log I)`\ 复杂度的向量搜索问题，其中\ :math:`U`\ 是用户数量，\ :math:`I`\ 是物品数量。

两大技术路径的演进轨迹
~~~~~~~~~~~~~~~~~~~~~~

**i2i召回的核心是序列建模**\ 。从Word2Vec的分布假说出发，所有i2i方法都在探索同一个本质问题：如何更好地定义和利用“序列”来学习物品之间的相似性。这条路径展现了对“序列”概念不断深化的过程——从最直接的用户行为序列（Item2Vec），到融入属性信息弥补序列稀疏性的增强方法（EGES），再到将业务目标融入序列学习的实践探索（Airbnb），最终发展为从复杂图结构中动态挖掘序列的前沿技术（PinSage）。

**u2i召回的核心是双塔架构**\ 。这条路径体现了模型表示能力的持续增强：从因子分解的经典数学原型（FM），到深度学习的标准化实现（DSSM），最终演进为更符合推荐本质的生成式预测范式（YouTubeDNN）。双塔模型的成功在于找到了效果与效率的最佳平衡点——用户塔和物品塔的解耦设计使得物品向量可以离线预计算，而用户向量可以实时计算，然后通过高效的最近邻搜索完成召回。

向量召回的统一使命
~~~~~~~~~~~~~~~~~~

尽管技术路径不同，所有向量召回模型的最终使命都是统一的：在保证极高效率的前提下，从海量物料库中快速、准确地筛选出一个几百到上千的候选集，与用户兴趣高度相关。向量召回追求的是“宁可错杀，不能放过”的高召回率，它的职责是构建一个覆盖面广泛的候选池，为后续的精排模型提供充足的优化空间。

技术边界与发展方向
~~~~~~~~~~~~~~~~~~

向量召回在解决传统协同过滤局限性方面取得了显著成功，但也面临着新的挑战。表示瓶颈是一个核心问题——将复杂的用户兴趣和物品特性压缩到固定维度的向量中，不可避免地会损失信息。特别是对于兴趣多样化的用户，单一向量难以全面刻画其偏好。静态性限制也不容忽视——预计算的物品向量无法实时反映用户的即时反馈和兴趣变化。

更深层的挑战在于序列建模的局限性。无论是i2i的共现序列还是u2i的行为历史，都主要关注相邻元素间的关系，对长期依赖和复杂序列模式的捕捉能力有限。现实中用户的兴趣演化往往呈现出复杂的时序特征，可能存在周期性模式、突发性兴趣转移、多兴趣并行发展等现象，这些都难以用简单的向量表示充分描述。

用户行为本质上是一个时序过程，包含着丰富的序列模式和动态特征。如何更好地建模这种序列性，如何捕捉用户兴趣的时序演化规律，如何处理多兴趣的并行发展，这些都是下一代召回技术需要解决的核心问题。接下来我们将探讨专门针对序列建模的召回方法，这些方法不再满足于静态的向量表示，而是深入挖掘用户行为序列中的时序依赖关系，通过更精细的序列建模技术来提升召回的准确性和多样性。
